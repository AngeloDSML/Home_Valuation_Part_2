{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial Part 2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lhttaPaFVFG"
      },
      "source": [
        "### **Quick Tutorial - Machine Learning Models for Residential Appraisers, Part 2**\n",
        "### **Random Forest and Extreme Gradient Boosting (XGBoost)**\n",
        "\n",
        "&nbsp;  \n",
        "*Important Note: There are plenty of free machine learning tutorials and courses online. Anyone can access them, learn, and run predictive models for home values. However, this tutorial has been designed specifically for residential appraisers, and some of the material will be irrelevant or less important for other industries. If you are not a residential appraiser, and/or you are looking to learn about machine learning as a broader field, this tutorial may not be adequate for you.*\n",
        "\n",
        "The purpose of this tutorial is for residential appraisers interested in machine learning to get their toes wet. This is **not** a comprehensive machine learning tutorial and it does **not** cover everything there is to know about the topic. \n",
        "\n",
        "\n",
        "&nbsp;  \n",
        "**Prerequisites:**\n",
        "1.\tSome understanding of Python programming.\n",
        "2.\tAccess and familiarity with Jupyter notebook.\n",
        "3.\tIf you want to use your own data you will need access to home sales data and custom exports from your local MLS.\n",
        "\n",
        "&nbsp;  \n",
        "**Obtain the data:**\n",
        "We will be using a dataset of home sales that includes sales prices and several predicting features, in csv format ***(Already pre-processed from Part 1 of the tutorial)***. \n",
        "\n",
        "The easiest way to obtain a dataset for your specific market area is by creating a custom csv export from your local MLS system. If you don’t know how to create it you should get technical support from your MLS provider.\n",
        "\n",
        "The sales dataset  contains the following features:\n",
        "Lot size, Water View, Year Built, Bedrooms, Bathrooms, GLA, Garage, Carport, Fireplace, Pool, and Sales Price.\n",
        "Note: These features are based on the subject’s market area. You should export a dataset that includes all of the value-affecting features you consider relevant for your specific market area. \n",
        "\n",
        "&nbsp;  \n",
        "**Assumptions:**\n",
        "We will make the following assumptions for the purpose of this tutorial. \n",
        "1.\tStable market condition. In rapidly increasing or decreasing markets you will likely need to add a “sales date” column/feature.\n",
        "2.\tAccurate data sources. MLS data is considered to be good and reliable.\n",
        "3.\tRelevant predicting features. Make sure you include all of the appropriate value-affecting features for the subject’s market area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49NM76jSdSmm"
      },
      "source": [
        "### **IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClR2XS8cXerE"
      },
      "source": [
        "#### First, we need to import the libraries we are going to be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqawxvpFcsW6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maHZ7kfIdqzE"
      },
      "source": [
        "### **IMPORT DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNyOh3z_Hce6"
      },
      "source": [
        "#### Next, we import the homes sales dataset to our notebook. (The dataset is already pre-processed from Part 1 of the tutorial) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayPdMqp8dKRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0119a971-13c8-4216-a0e1-4fd81bfbb38a"
      },
      "source": [
        "file_path = '/content/Sales_Dataset2.csv'       #Create file path to csv dataset\n",
        "sales_df = pd.read_csv(file_path)               #Read dataset and assign the name sales_df\n",
        "sales_df.head()                                 #Display data (first 5 rows) to make sure it was successfully imported"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site</th>\n",
              "      <th>View</th>\n",
              "      <th>Age</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>GLA</th>\n",
              "      <th>Garage</th>\n",
              "      <th>Fireplace</th>\n",
              "      <th>Pool</th>\n",
              "      <th>Sales_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8549</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4439</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11108</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4069</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9920</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3834</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>515000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10035</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3828</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>495000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9600</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3382</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>494700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Site  View  Age  Bedrooms  ...  Garage  Fireplace  Pool  Sales_Price\n",
              "0   8549     1    5         5  ...       3          0     1       675000\n",
              "1  11108     0    3         5  ...       3          0     0       540000\n",
              "2   9920     0   22         5  ...       3          1     1       515000\n",
              "3  10035     1   22         5  ...       3          1     1       495000\n",
              "4   9600     1   14         5  ...       3          0     1       494700\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ9yK2X14Yju"
      },
      "source": [
        "#### Every time we modify the dataframe it is a good practice to check a sample of it to confirm the code did what was intended. For this we will use sales_df.head(), which will show the first 5 rows of the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPwwoczaH8_W"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### **EXPLORE THE DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chlPVOarIDQI"
      },
      "source": [
        "#### Now we can explore the characteristics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Sx1N6tH4sW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "730645b0-56d6-4cfa-fb3a-38014d7cde2a"
      },
      "source": [
        "sales_df.describe()     #Get main statistics of the dataset"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site</th>\n",
              "      <th>View</th>\n",
              "      <th>Age</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>GLA</th>\n",
              "      <th>Garage</th>\n",
              "      <th>Fireplace</th>\n",
              "      <th>Pool</th>\n",
              "      <th>Sales_Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8608.233333</td>\n",
              "      <td>0.195238</td>\n",
              "      <td>20.461905</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>2.466667</td>\n",
              "      <td>2183.052381</td>\n",
              "      <td>4.128571</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>306573.128571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2779.318027</td>\n",
              "      <td>0.397331</td>\n",
              "      <td>4.749311</td>\n",
              "      <td>0.641842</td>\n",
              "      <td>0.611949</td>\n",
              "      <td>596.492637</td>\n",
              "      <td>26.066489</td>\n",
              "      <td>0.364805</td>\n",
              "      <td>0.472531</td>\n",
              "      <td>71470.906697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1684.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1191.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>167850.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6577.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1805.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>259925.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8115.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2023.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>285000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10080.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2454.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>340750.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18439.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4439.000000</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>675000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Site        View  ...        Pool    Sales_Price\n",
              "count    210.000000  210.000000  ...  210.000000     210.000000\n",
              "mean    8608.233333    0.195238  ...    0.333333  306573.128571\n",
              "std     2779.318027    0.397331  ...    0.472531   71470.906697\n",
              "min     1684.000000    0.000000  ...    0.000000  167850.000000\n",
              "25%     6577.500000    0.000000  ...    0.000000  259925.000000\n",
              "50%     8115.500000    0.000000  ...    0.000000  285000.000000\n",
              "75%    10080.000000    0.000000  ...    1.000000  340750.000000\n",
              "max    18439.000000    1.000000  ...    1.000000  675000.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9lqCsQuYJQ5",
        "outputId": "85a98bc4-a4cd-4d30-ce10-3dd8936319a5"
      },
      "source": [
        "sales_df.info()         #Get general information including number of rows, columns, and data types"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 210 entries, 0 to 209\n",
            "Data columns (total 10 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Site         210 non-null    int64  \n",
            " 1   View         210 non-null    int64  \n",
            " 2   Age          210 non-null    int64  \n",
            " 3   Bedrooms     210 non-null    int64  \n",
            " 4   Bathrooms    210 non-null    float64\n",
            " 5   GLA          210 non-null    int64  \n",
            " 6   Garage       210 non-null    int64  \n",
            " 7   Fireplace    210 non-null    int64  \n",
            " 8   Pool         210 non-null    int64  \n",
            " 9   Sales_Price  210 non-null    int64  \n",
            "dtypes: float64(1), int64(9)\n",
            "memory usage: 16.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbL0cUh6ouFk"
      },
      "source": [
        "&nbsp;\n",
        "####Since we already covered the data pre-processing steps in Part 1, we will not cover those steps again in Part 2. Instead, we will jump right into data modeling and predictions.\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kTna94fpu2i"
      },
      "source": [
        "#### **MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApM6WL7I2a8"
      },
      "source": [
        "#### First, we import the libraries we are going to be using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jtw44jMPjGR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GGxPVepHzuO"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### Before running our models we must define the predicting features (Site, View, Age, Bedrooms, Bathrooms, GLA, Garage, Fireplace, and Pool) as 'X' and the target feature (Sales Prices) as 'y'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOwqPdjop8Ji"
      },
      "source": [
        "X = sales_df.iloc[:,:-1]      #Define predicting features, X\n",
        "y = sales_df.iloc[:,-1]       #Define target, y"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu9Lr2dsJY-s"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### Next, we split the dataframe in two sets. The train set (to train the model) and the test set (to test the model with new data).\n",
        "#### We assign 80% of the data to the train set and 20% to the test set. (Other common combinations are 75/25, 85/15, and 90/10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaGZL7d_Jxzy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.2, random_state=0)     #train-test split"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seapE5RxPH6R"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "\n",
        "#### **MODEL: Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up0Vr5qDK8Bw"
      },
      "source": [
        "\n",
        "#### The next step is to define the random forest model and fit the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdG1BAhjwqJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e198af05-19b8-4761-bf9a-7d32af864e76"
      },
      "source": [
        "random_forest = RandomForestRegressor(random_state=0)   #Define the model\n",
        "\n",
        "random_forest.fit(X_train,y_train)                      #Fit the train set\n"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=0, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giOSu1bcL1GH"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### Now that the Random Forest model has been created, we want to know how well it performs with new data (test set). We will use \"Mean Absolute Error\" (MAE) to score the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkbaCo0MQCJ",
        "outputId": "a96d623b-6cf1-4deb-d968-f4262e1f887c"
      },
      "source": [
        "rf_pred = random_forest.predict(X_test)                     #Get predictions using the test set\n",
        "\n",
        "rf_mae = mean_absolute_error(rf_pred, y_test)               #Calculate MAE\n",
        "\n",
        "print(\"Random Forest MAE:\", format(rf_mae, ',.2f'))         #Display MAE score"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest MAE: 17,733.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVLSLu0I2MTs"
      },
      "source": [
        "#### The Mean Absoulte Error (MAE) is 17,733.81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM19UomwRFua"
      },
      "source": [
        "&nbsp; \n",
        "&nbsp; \n",
        "#### Next, we can work on the Extreme Gradient Boosting (XGBoost) model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sCPLUGyr3zb"
      },
      "source": [
        "####**MODEL: Extreme Gradient Boosting (XGBoost)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Wt7ITgSWiD"
      },
      "source": [
        "#### Let's define the model and fit the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otNQwhNSja_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c04bb1-8e75-46ac-c2f2-248219d53e5e"
      },
      "source": [
        "xg_boost = XGBRegressor()             #Define the model\n",
        " \n",
        "xg_boost.fit(X_train,y_train)         #Fit the train set"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[23:39:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07tpVfN5SzyO"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### We just created the Extreme Gradient Boosting model. Now we want to know how well it performs with new data (test set). We will use \"Mean Absolute Error\" (MAE) to score the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-5_uZlKSyVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987559d5-b9bb-4e1a-f0aa-701604f8ea85"
      },
      "source": [
        "xgb_pred = xg_boost.predict(X_test)                 #Get predictions using the test set\n",
        "\n",
        "xgb_mae = mean_absolute_error(xgb_pred,y_test)      #Calculate MAE\n",
        "\n",
        "print(\"XGBoost MAE:\", format(xgb_mae, ',.2f'))      #Display MAE score\n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBoost MAE: 20,499.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXY-_Kyb2v0K"
      },
      "source": [
        "#### The Mean Absoulte Error (MAE) is 20,499.17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS4XtRgxWCmI"
      },
      "source": [
        "#### Based on the MAE scores it appears that the **Random Forest** model, with a lower MAE, is a better fit for our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrObnivyWj59"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### Next, we will run both of the trained models using the subject property data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsJeV2XPs_XD"
      },
      "source": [
        "#### **PREDICTIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za7s0g65WywE"
      },
      "source": [
        "#### Import a csv file that contains the subject's information in the same format as the cleaned dataframe. The only missing feature is the \"Sales Price\" since that is the target we are trying to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MLzGKgrktnyj",
        "outputId": "c55f1bcd-89a0-4c48-d9d6-fa89eddcf6c6"
      },
      "source": [
        "sp_data_path = '/content/SP_Data2.csv'          #Create file path to csv dataset \n",
        "sp_data = pd.read_csv(sp_data_path)             #Read dataset in dataframe\n",
        "\n",
        "sp_data.head()                                  #Display data (first 5 rows) just to make sure it was successfully imported"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site</th>\n",
              "      <th>View</th>\n",
              "      <th>Age</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>GLA</th>\n",
              "      <th>Garage</th>\n",
              "      <th>Fireplace</th>\n",
              "      <th>Pool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12100</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2915</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Site  View  Age  Bedrooms  Bathrooms   GLA  Garage  Fireplace  Pool\n",
              "0  12100     0   16         4          3  2915       3          0     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MknaQcljbJHn"
      },
      "source": [
        "&nbsp;\n",
        "\n",
        "&nbsp;  \n",
        "#### Now we define the predicting features and then we are run the trained models to predict the subject's estimated value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o0tnsZuaaxO",
        "outputId": "6a4b9f94-a259-487e-c545-898a155a9e56"
      },
      "source": [
        "features = ['Site', 'View', 'Age', 'Bedrooms', 'Bathrooms', 'GLA','Garage','Fireplace','Pool']    #Define predicting features\n",
        "sp_X = sp_data[features]\n",
        "\n",
        "prediction_random_forest = int(random_forest.predict(sp_X))           #Predict the subject's value using Random Forest model\n",
        "prediction_xgboost = int(xg_boost.predict(sp_X))                      #Predict the subject's value using Extreme Gradient Boosting model\n",
        "\n",
        "print('Estimated Values')                                             #Display estimated values\n",
        "print()\n",
        "print('Random Forest: $', format(prediction_random_forest,','))\n",
        "print('Extreme Gradient Boosting: $', format(prediction_xgboost,','))"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated Values\n",
            "\n",
            "Random Forest: $ 395,426\n",
            "Extreme Gradient Boosting: $ 407,910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOV9Kz32nRaP"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;  \n",
        "#### Subject's estimated value:\n",
        "#### 1) Based on Random Forest is 395,426\n",
        "#### 2) Based on Extreme Gradient Boosting is 407,910"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0--_bh-4H6DP"
      },
      "source": [
        "&nbsp;  \n",
        "&nbsp;\n",
        "#### **What to do with the results?**\n",
        "\n",
        "#### Similar to Part 1 of the tutorial, we were able to run a couple of models that predicted a property value with reasonable accuracy. However, the fact that our models produced these results doesn’t mean that we must use them to derive a final estimate of value. Perhaps we just want them as an additional tool to support our own analysis. Or maybe we do want to use them for low-risk collateral analysis. The point is that we should always keep in mind that machine learning models are just tools, we are ultimately in charge of making the decision to use them or not. \n",
        "&nbsp;\n",
        "\n",
        "#### **Conclusion**\n",
        "#### In Part 2 of this tutorial we covered data collection, data modeling, and prediction of values.\n",
        "&nbsp;\n",
        "#### In summary, the estimated values obtained from our four models are:\n",
        "#### Linear Regression: 403,911 \n",
        "#### Decision Tree: 420,000\n",
        "#### Random Forest: 395,426\n",
        "#### Extreme Gradient Boosting: 407,910\n",
        "&nbsp;\n",
        "\n"
      ]
    }
  ]
}